---
title: "analyze_refgame_dataframe"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
library(lme4)
library(lmerTest)
#library(brms)
library(broom.mixed)
library(tidyboot)
```

# Import group data

```{r}
# 'cogsci' or '2.0, i.e. no interrupting & balanced contexts'
version = 'cogsci'
prefix = '../../results/csv/graphical_conventions'
path = ifelse(version == 'cogsci', 'run3run4.csv', 'run5_submitButton.csv')

d <- paste0(prefix, '_group_data_', path) %>%
  read_csv() %>% 
  select(-png)

d.bis.drawDuration.raw <- paste0(prefix, '_bis_drawDuration_', path) %>%
  read_csv() %>% 
  select(-X1)

d.bis.numStrokes <- paste0(prefix, '_bis_numStrokes_', path) %>% 
  read_csv() %>%
  select(-X1)
```
## Preprocess BIS data

To center every condition at the same starting point, we generate a "baseline" data-frame that computes BIS for the "pre-" phase, grouping by condition and gameID.

Then we add this "baseline" bis to each row of original bis dataframe.

```{r}
d.bis.drawDuration <- d.bis.drawDuration.raw %>%
  filter(repetition==0) %>%
  group_by(condition,gameID) %>%
  summarize(bis_baseline = mean(bis)) %>%
  inner_join(d.bis.drawDuration.raw, 
             by = c('condition','gameID'), 
             suffix = c("","_baseline")) %>%
  mutate(bis_relative = bis - bis_baseline,
         repetition_1 = repetition + 1)
```

Some basic statistics about the dataset to report

```{r}
numGames <- d %>% 
  pull(gameID) %>%
  unique() %>%
  length()

cat("we collected", numGames, "games")
```

# Behavioral Results
## Section 2.1 Participants learn to communicate more effectively

To get 95% CIs for Fig. 1, we bootstrap re-sample within each condition & repetition

```{r}
d.bis.drawDuration %>% 
  group_by(condition, repetition_1) %>% 
  tidyboot_mean(bis_relative) %>%
  ggplot(aes(x=repetition_1, y=empirical_stat, color=condition, fill=condition)) + 
    geom_line(size=1.5)+
    geom_ribbon(aes(ymin=ci_lower, ymax = ci_upper), alpha=.25, color=NA,
                data = . %>% filter(condition == 'repeated')) + 
    geom_errorbar(aes(ymin=ci_lower, ymax = ci_upper), width = 0, size = 1.5,
                  data = . %>% filter(condition == 'control')) + 
    labs(y = "relative efficiency", x = "repetition") +
    #scale_x_continuous(breaks = seq(1,8)) + 
    scale_y_continuous(breaks = seq(-0.5,2.5,0.5)) +
    scale_color_manual(values=c("#808080", "#163c4e")) + 
    scale_fill_manual(values=c("#808080", "#163c4e")) + 
    theme_few() +
    theme(legend.position = c(0.8, 0.2), 
          text = element_text(size=18), 
          element_line(size=1), 
          element_rect(size=2, color="#00000"))

ggsave('../../results/plots/refgame_BIS_timeseries.pdf', width=14, height = 10, units='cm')

```

Simple effect of BIS in repetition condition

```{r}
d.bis.drawDuration %>%
  filter(condition == 'repeated') %>%
  mutate(repetition = scale(repetition)) %>%
  lmer(bis ~ repetition + (1 + repetition | gameID),
      data = .,
      control=lmerControl(optimizer = 'bobyqa')) %>%
  summary()
```

Simple effect of (only) pure draw duration in repetition condition

```{r}
d %>%
  filter(condition == 'repeated') %>%
  mutate(repetition = scale(repetition)) %>%
  lmer(drawDuration ~ repetition + (1 + repetition | gameID),
      data = .,
      control=lmerControl(optimizer = 'bobyqa')) %>%
  summary()
```

Simple effect of (only) accuracy in repetition condition

```{r}
d %>%
  filter(condition == 'repeated') %>%
  mutate(repetition = scale(repetition)) %>%
  glmer(outcome ~ repetition + (1 + repetition | gameID),
      data = .,
      family='binomial',
      control=glmerControl(optimizer = 'bobyqa')) %>%
  summary()
```

Simple effect of number of strokes in repeated condition.

```{r}
d %>% 
  filter(condition=='repeated') %>%
  lmer(numStrokes ~ repetition + (1 + repetition | gameID), 
       data = .) %>%
  summary()
```
Make figure of number of strokes over time in repeated condition

```{r}
d %>%
  filter(condition == 'repeated') %>%
  mutate(repetition = repetition + 1) %>%
  group_by(repetition) %>%
  tidyboot_mean(numStrokes) %>%
  ggplot(aes(x = repetition, y = empirical_stat)) +
    geom_point(colour = '#163c4e',size = 2) +
    geom_smooth(method = 'lm', formula = y ~ poly(x, 2), se = F, color = '#163c4e') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, color = '#163c4e') +
    theme_few() +
    scale_x_continuous(labels = c(1,2,3,4,5,6,7,8), breaks = c(1,2,3,4,5,6,7,8)) +
    ylab('number of strokes') +
    #ylim(1,8) +
    theme(legend.position = c(0.5, 0.8), text = element_text(size=18), 
          element_line(size=1), element_rect(size=2, color="#00000")) 
  
ggsave('../../../graphical_conventions_latex/cogsci19/figures/source/num_strokes.pdf', height = 10, width = 7, units = 'cm', useDingbats = F)
```

## Section 2.2 Conventions are object-specific

No accuracy differences between condition in pre phase 

```{r}
d %>%
  mutate(phase = as.factor(ifelse(repetition == 0, 'pre', 'post')),
        condition = as.factor(condition)) %>%
  filter(phase == 'pre') %>%
  group_by(gameID, condition) %>%
  summarize(acc = mean(outcome)) %>%
  spread(condition, acc) %>%
  mutate(diff = repeated - control) %>%
  gather(metric, value, repeated, control, diff) %>%
  group_by(metric) %>%
  tidyboot_mean(value)
```

Now we run a mixed-effects model to evaluate an interaction in BIS changes across conditions. The maximal model for the interaction between repetition and condition is

```
interaction_lmm <- lmer(bis ~ phase * condition + (1 + phase*condition | target) + (1 + phase*condition | gameID)
```

For convergence, we needed to remove target-wise random effects and switch to optimization algorithm in lme.

```{r}
d.bis.drawDuration %>%
  ungroup() %>%
  filter(repetition == 0 | repetition == 7) %>% 
  mutate(phase = as.factor(ifelse(repetition == 0, 'pre', 'post')),
         condition = as.factor(condition)) %>%
  nlme::lme(bis ~ phase * condition,
            random = ~ phase * condition | gameID,
            data = .,
            contrasts = list(phase = contr.sum(2), condition = contr.sum(2)),
            control = nlme::lmeControl(opt='optim', maxIter = 1000)) %>%
  summary()
```

Double-check mixed-effects model just on accuracy

```{r}
d %>%
  filter(phase %in% c('pre', 'post')) %>% 
  mutate(phase = as.factor(phase),
         condition = as.factor(condition),
         outcome = as.factor(outcome)) %>%
  glmer(outcome ~ phase * condition + (1 +phase*condition  | gameID),
        family = 'binomial',
        control=glmerControl(optimizer = 'bobyqa'),
        data = .) %>%
  summary()
```

Raw accuracy diff in pre and post

```{r}
d %>%
  filter(phase== 'pre'| phase == 'post') %>%
  group_by(gameID,phase,condition) %>%
  summarize(accuracy=mean(outcome)) %>%
  spread(phase, accuracy) %>%
  mutate(diff = post - pre) %>%
  group_by(condition) %>%
  tidyboot_mean(diff) 
```

To measure within-interaction convergence on sketch features, first import pre-processed matrices geneated in ipynb...

```{r}
source('./helpers.R')
library(broom)
detach('package:lmerTest')
prefix <- '../../data/sketch_features/no_crop/'
M_mat = read_csv(paste0(prefix, 'METADATA_sketch.csv')) %>%
  filter(condition == 'repeated') %>%
  select(gameID, target, repetition, trial_num, feature_ind) %>%
  mutate(feature_ind = feature_ind + 1,
         trial_num = as.numeric(trial_num),
         repetition = as.numeric(repetition)) %>% # Have to correct for R 1-indexing...
  arrange(gameID, target, repetition) 
F_mat_raw_nonorm = read_delim(paste0(prefix, 'FEATURES_FC6_sketch_no-channel-norm.txt'),
                              delim=',', col_names=F) %>%
  as.matrix()

colnames(F_mat_raw_nonorm) <- NULL
```
run stats

```{r}
true_lmer.within <- make_within_df(M_mat, F_mat_raw_nonorm, 'cor') %>% 
  filter(rep2 == rep1 + 1) %>% 
  ungroup()
summary(lmer(sim ~ poly(rep1,2) + (1  | gameID) + (1 | target), data = true_lmer.within))
```

Null baseline

```{r}
# permuted_tstats.within <- map_dbl(seq_len(1000), ~ M_mat %>%
#  # scramble repetition
#   group_by(target, repetition) %>%
#   mutate(gameID = sample(gameID)) %>% 
#   ungroup() %>%
#   arrange(gameID, target, repetition) %>%
#   make_within_df(F_mat_raw_nonorm, 'cor') %>%
#   filter(rep2 == rep1 + 1) %>% 
#   # turn into a list to make `map` happy
#   ungroup() %>%  
#   mutate(sample_id = 1) %>% 
#   split(.$sample_id) %>%
#   map(~ lmer(sim ~ poly(rep1,2) + (1 | gameID) + (1 | target), data = .)) %>%
#   map(~ (tidy(., effects = 'fixed') %>% filter(term == 'poly(rep1, 2)1'))$statistic) %>%
#   unlist())
# 
# cat('CI for within analysis=', sort(permuted_tstats.within)[25], sort(permuted_tstats.within)[975])
```

compute both true empirical & permuted output

```{r}
num_permutations <- 1000
empirical.within <- compute_within_convergence(M_mat, F_mat_raw_nonorm, 
                                               'empirical', method = 'cor', nboot = 1000)
# baselines.within <- map_dfr(seq_len(num_permutations), ~M_mat %>%
#   group_by(target, repetition) %>%
#   mutate(gameID = sample(gameID)) %>% # shuffle within target-rep 
#   ungroup() %>%
#   arrange(gameID, target, repetition) %>%
#   compute_within_convergence(F_mat_raw_nonorm, .x, method = 'cor')) # this passes in the iteration number
```

Make Fig. 5C

```{r}
# d.toplot <- baselines.within %>%
#   group_by(`rep diff`) %>%
#   summarize(`ci_upper`=quantile(empirical_stat, probs=0.975),
#             `ci_lower`=quantile(empirical_stat, probs=0.025),
#             `empirical_stat`=quantile(empirical_stat, probs=0.5)) %>%
#   mutate(sample_id = 'baseline') %>%
#   rbind(empirical.within %>% select(-n, -mean))

ggplot(empirical.within, aes(x = `rep diff`, y = empirical_stat, 
                     fill = sample_id, color = sample_id, group = sample_id)) +
    # geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), alpha = 0.5, color = NA,
    #             d.toplot %>% filter(sample_id == 'baseline')) +
    #geom_line(alpha = 0, size = 2) +
    # geom_line(size = 1, linetype = 'dashed', 
    #           data = . %>% filter(sample_id == 'baseline')) +
    geom_point(size = 2, 
               data = . %>% filter(sample_id == 'empirical')) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                  data = . %>% filter(sample_id == 'empirical')) +
    geom_smooth(method = 'lm', formula = y ~ poly(x, 2), se = F,
                data = . %>% filter(sample_id == 'empirical')) +
    scale_color_manual(values=c("#d07e93", "#163c4e")) + 
    scale_fill_manual(values=c("#d07e93", "#163c4e")) + 
    scale_x_discrete(labels = c('(1,2)','(2,3)', '(3,4)', '(4,5)', '(5,6)' ,'(6,7)','(7,8)')) +
    ylim(.5, .8) +
    ylab('correlation') +
    ggtitle('within-pair') +
    theme_few() +
    xlab('repetition pair') +
    guides(color = F, fill = F) +
    theme(legend.position = c(0.5, 0.8), text = element_text(size=18), 
          element_line(size=1), element_rect(size=2, color="#00000"))

ggsave('../../../graphical_conventions_latex/cogsci19/figures/source/within.pdf', height = 10, width = 7, units = 'cm', useDingbats = F)
```

## Section 2.3: Conventions are interaction-specific 


### Interaction history contributes to gains in recognition performanc

Compute between-interaction divergence 

```{r}
gamepair.df <- M_mat %>%
  group_by(target, repetition) %>%
  do(flatten_sim_matrix(get_sim_matrix(., F_mat_raw_nonorm, method = 'cor'),
                        .$gameID)) %>%
  unite(col = 'gamepair', dim1, dim2)

true_lmer.across <- lmer(sim ~ poly(repetition, 2) + (1 + repetition | gamepair) + (1 + repetition | target), data = gamepair.df)
true_tstat.across <- coef(summary(true_lmer.across))[,"t value"][2]

# permuted_tstats.across <- map_dbl(seq_len(1000), ~ M_mat %>%
#  # scrambles repetition
#   group_by(target, gameID) %>%
#   mutate(repetition = sample(repetition, size = length(repetition))) %>% 
#   ungroup() %>%
#   arrange(gameID, target, repetition) %>%
#   group_by(target,repetition) %>%
#   # computes similarity upper triangular
#   do(flatten_sim_matrix(get_sim_matrix(., F_mat_raw_nonorm, method = 'cor'), .$gameID)) %>%
#   unite(col = 'gamepair', dim1, dim2) %>%
#   mutate(sample_id = 1) %>%
#   ungroup() %>%
#   # turns into a list to make `map` happy
#   split(.$sample_id) %>%
#   map(~ lmer(sim ~ poly(repetition,2) + (1 + repetition | gamepair) + (1 + repetition | target), data = .)) %>%
#   map(~ (tidy(., effects = 'fixed') %>% filter(term == 'poly(repetition, 2)1'))$statistic) %>%
#   unlist())
# 
# cat('CI=', sort(permuted_tstats.across)[25], sort(permuted_tstats.across)[975])
```

```{r}
empirical.across <- compute_across_similarity(M_mat, F_mat_raw_nonorm,   
                                              'raw_cor_nonorm', method = 'cor', nboot = 1000)
# baselines.across <- map_dfr(seq_len(1000), ~M_mat %>%
#   group_by(target, gameID) %>%
#   mutate(repetition = sample(repetition, size = length(repetition))) %>% 
#   ungroup() %>%
#   compute_across_similarity(F_mat_raw_nonorm, .x, method = 'cor')) 
```

```{r}
# d.toplot <- rbind(empirical.across %>% select(-mean, -n),
#       baselines.across %>% 
#         group_by(repetition) %>%
#         summarize(`ci_upper`=quantile(empirical_stat, probs=0.975),
#                   `ci_lower`=quantile(empirical_stat, probs=0.025),
#                   `empirical_stat`=quantile(empirical_stat, probs=0.5)) %>%
#         mutate(sample_id = 'baseline')) %>%
#         mutate(repetition = repetition + 1)
ggplot(d.toplot, aes(x = repetition, y = empirical_stat, group = sample_id, 
                     color = sample_id, fill=sample_id)) +
  geom_ribbon(alpha = 0.25, aes(ymin = ci_lower, ymax = ci_upper), color = NA,
              data = d.toplot %>% filter(sample_id == 'baseline')) + 
  geom_line(size = 1, linetype = 'dashed', data = d.toplot %>% filter(sample_id == 'baseline')) +
  geom_point(size = 2, alpha = 1, data = d.toplot %>% filter(sample_id == 'raw_cor_nonorm')) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                 data = d.toplot %>% filter(sample_id == 'raw_cor_nonorm')) +
  geom_smooth(method = 'lm', formula = y ~ poly(x, 2), se = F,
              data = d.toplot %>% filter(sample_id == 'raw_cor_nonorm')) +
  scale_color_manual(values=c("#d07e93", "#163c4e")) + 
  scale_fill_manual(values=c("#d07e93", "#163c4e")) + 
  xlim(0.5, 8.5) +
  scale_x_continuous(labels = c(1,2,3,4,5,6,7,8), breaks = c(1, 2,3,4,5,6,7,8)) +
  ylim(.5, .8) +
  ylab('correlation') +
  ggtitle('between-pair') +
  theme_few() +
  guides(color = F, fill = F) +
  theme(legend.position = c(0.5, 0.8), text = element_text(size=18), 
        element_line(size=1), element_rect(size=2, color="#00000"))


ggsave('../../../graphical_conventions_latex/cogsci19/figures/source/across.pdf', height = 10, width = 7, units = 'cm', useDingbats = F)
```

## Temporal structure 


# Supplemental

## Histograms for bis, numCurvesPerSketch and numStrokes 

```{r}
d.bis.drawDuration %>% 
  ggplot(aes(x = bis)) +
    geom_histogram(bins=50)
```

```{r}
d %>% 
  group_by(numCurvesPerSketch) %>% 
  ggplot(aes(x = numCurvesPerSketch)) +
    geom_histogram()
```

```{r}
d %>% 
  group_by(numStrokes) %>% 
  ggplot(aes(x = numStrokes)) + 
    geom_histogram()
```

## Within-interaction drift

```{r}
true_lmer.drift <- make_within_df(M_mat, F_mat_raw_nonorm, 'cor') %>% 
  filter(rep1 == 0) %>% 
  ungroup()
true_lmer.drift.out <- lmer(sim ~ poly(rep2,2) + (1  | gameID) + (1 | target), data = true_lmer.drift)

permuted_tstats.drift <- map_dbl(seq_len(1000), ~ M_mat %>%
 # scrambles repetition
  group_by(target, repetition) %>% mutate(gameID = sample(gameID)) %>% ungroup() %>%
  arrange(gameID, target, repetition) %>%
  make_within_df(F_mat_raw_nonorm, 'cor') %>%
  filter(rep1 == 0) %>% 
  # turns into a list to make `map` happy
  ungroup() %>%  mutate(sample_id = 1) %>% split(.$sample_id) %>%
  map(~ lmer(sim ~ poly(rep2,2) + (1 | gameID) + (1 | target), data = .)) %>%
  map(~ (tidy(., effects = 'fixed') %>% filter(term == 'poly(rep2, 2)1'))$statistic) %>%
  unlist())

cat('CI for drift analysis=', sort(permuted_tstats.drift)[25], sort(permuted_tstats.drift)[975])
cat('true for drift analysis=', (tidy(true_lmer.drift.out, effects = 'fixed') %>% filter(term == 'poly(rep2, 2)1'))$statistic)
```

```{r}
num_permutations <- 1000
empirical.drift <- compute_within_drift(M_mat, F_mat_raw_nonorm, 'empirical', method = 'cor', nboot = 1000)
baselines.drift <- map_dfr(seq_len(num_permutations), ~M_mat %>%
  group_by(target, repetition) %>%
  mutate(gameID = sample(gameID)) %>% # shuffle within target-rep 
  ungroup() %>%
  arrange(gameID, target, repetition) %>%
  compute_within_drift(F_mat_raw_nonorm, .x, method = 'cor')) # this passes in the iteration number
```

```{r}
d.toplot.drift <- baselines.drift %>%
  group_by(`rep diff`) %>%
  summarize(`ci_upper`=quantile(empirical_stat, probs=0.975),
            `ci_lower`=quantile(empirical_stat, probs=0.025),
            `empirical_stat`=quantile(empirical_stat, probs=0.5)) %>%
  mutate(sample_id = 'baseline') %>%
  rbind(empirical.drift %>% select(-n, -mean)) 

ggplot(d.toplot.drift, aes(x = `rep diff`, y = empirical_stat, 
             fill = sample_id, color = sample_id, group = sample_id)) +
    geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), alpha = 0.5, color = NA,
                d.toplot.drift %>% filter(sample_id == 'baseline')) +
    #geom_line(alpha = 0, size = 2) +
    geom_line(size = 1, linetype = 'dashed', data = d.toplot.drift %>% filter(sample_id == 'baseline')) +
    geom_point(size = 2, data = d.toplot.drift %>% filter(sample_id == 'empirical')) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0,
                  data = d.toplot.drift %>% filter(sample_id == 'empirical')) +
    geom_smooth(method = 'lm', formula = y ~ poly(x, 2), se = F,
                data = d.toplot.drift %>% filter(sample_id == 'empirical')) +
    scale_color_manual(values=c("#d07e93", "#163c4e")) + 
    scale_fill_manual(values=c("#d07e93", "#163c4e")) + 
    scale_x_discrete(labels = c('(1,2)','(1,3)', '(1,4)', '(1,5)', '(1,6)' ,'(1,7)','(1,8)')) +
    ylim(.5, .8) +
    ylab('correlation') +
    ggtitle('drift from initial') +
    theme_few() +
    xlab('repetition pair') +
    guides(color = F, fill = F) +
    theme(legend.position = c(0.5, 0.8), text = element_text(size=18), 
          element_line(size=1), element_rect(size=2, color="#00000"))

ggsave('../../../graphical_conventions_latex/cogsci19/figures/source/drift.pdf', height = 10, width = 7, units = 'cm', useDingbats = F)
```

## Visualize effects of different pre-processing steps and distance metrics

```{r}
F_mat_raw_norm = as.matrix(read_delim('../../data/sketch_features/no_crop/FEATURES_FC6_sketch_channel-norm.txt',
                                   delim=',', col_names=F))
F_mat_PCA_nonorm = as.matrix(read_delim('../../data/sketch_features/no_crop/FEATURES_FC6_sketch_PCA_512_no-channel-norm.txt',
                                   delim=',', col_names=F))
F_mat_PCA_norm = as.matrix(read_delim('../../data/sketch_features/no_crop/FEATURES_FC6_sketch_PCA_512_channel-norm.txt',
                                   delim=',', col_names=F))

colnames(F_mat_raw_norm) <- NULL
colnames(F_mat_PCA_nonorm) <- NULL
colnames(F_mat_PCA_norm) <- NULL
rbind(compute_across_similarity(filtered_M, F_mat_raw_nonorm, 'raw_euclid_nonorm', method = 'euclidean'),
      compute_across_similarity(filtered_M, F_mat_raw_norm,   'raw_euclid_norm',   method = 'euclidean'),
      compute_across_similarity(filtered_M, F_mat_PCA_nonorm, 'PCA_euclid_nonorm', method = 'euclidean'),
      compute_across_similarity(filtered_M, F_mat_PCA_norm,   'PCA_euclid_norm',   method = 'euclidean'),
      compute_across_similarity(filtered_M, F_mat_raw_nonorm, 'raw_cor_nonorm',    method = 'cor'),
      compute_across_similarity(filtered_M, F_mat_raw_norm,   'raw_cor_norm',      method = 'cor'),
      compute_across_similarity(filtered_M, F_mat_PCA_nonorm, 'PCA_cor_nonorm',    method = 'cor'),
      compute_across_similarity(filtered_M, F_mat_PCA_norm,   'PCA_cor_norm',      method = 'cor')) %>%
      separate(sample_id, into = c('PCA', 'dist', 'norm')) %>%
      ggplot(aes(x = repetition, y = empirical_stat, color = norm)) + 
        #geom_line(alpha = 0.1) +
        geom_line() +
        geom_ribbon(aes(ymax = ci_upper, ymin = ci_lower), color = NA, alpha = .5) +
        theme_few() +
        facet_grid(dist ~ PCA, scales = 'free') +
        theme(aspect.ratio = 2)
  #geom_smooth(group = 1, method = 'loess')
  #geom_smooth(group = 1)
ggsave('unfiltered.pdf')
```

How well are these different steps correlated?

```{r}
rbind(compute_across_similarity(M_mat, F_mat_PCA_norm, 'PCA_cor_norm',    method = 'cor'),
      compute_across_similarity(M_mat, F_mat_raw_nonorm, 'raw_cor_nonorm',    method = 'cor')) %>%
      #separate(sample_id, into = c('PCA', 'dist', 'norm')) %>%
  select(repetition, sample_id, empirical_stat) %>%
  spread(sample_id, empirical_stat) %>%
  mutate(spcor = cor(PCA_cor_norm,raw_cor_nonorm, method='pearson')) %>%
  ggplot(aes(x = PCA_cor_norm, y = raw_cor_nonorm)) +
      geom_point() +
      geom_smooth() +
      theme_few()
```

Broken out by target

```{r}
M_mat %>%
  group_by(target, repetition) %>%
  do(flatten_sim_matrix(get_sim_matrix(., F_mat_raw_nonorm, method = 'cor'),
                        .$gameID)) %>%
  unite(col = 'gamepair', dim1, dim2) %>%
  ggplot(aes(x = repetition, y = sim, group = gamepair)) +
    geom_line(alpha = .1) +
    geom_smooth(method = 'lm', formula = y ~ poly(x, 2), group = 1) +
    facet_wrap(~ target) +
    theme_few()

ggsave('by_target_gamepair.pdf')
```